{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7bb177c-3b00-4b5d-b6f4-f0e4db59525d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       0.823440\n",
      "std        0.048295\n",
      "min        0.239000\n",
      "25%        0.821000\n",
      "50%        0.835000\n",
      "75%        0.852000\n",
      "max        0.870000\n",
      "Name: rounded_emissions, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       0.701669\n",
      "std        0.184643\n",
      "min        0.116000\n",
      "25%        0.681750\n",
      "50%        0.790500\n",
      "75%        0.821000\n",
      "max        0.865000\n",
      "Name: rounded_emissions, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\ground_data.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'rounded_emissions'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fae7b27e-6b3e-4ae7-a80f-9be2798f561b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       2.071562\n",
      "std        0.129863\n",
      "min        1.662420\n",
      "25%        1.994740\n",
      "50%        2.079390\n",
      "75%        2.170530\n",
      "max        2.396330\n",
      "Name: value, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       1.832134\n",
      "std        0.411359\n",
      "min        0.507470\n",
      "25%        1.721965\n",
      "50%        1.957115\n",
      "75%        2.103965\n",
      "max        2.313600\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\dataset_industry.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "476838c6-ce14-49e8-9401-607bfe9a9b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       3.302466\n",
      "std        0.291617\n",
      "min        2.531850\n",
      "25%        3.072060\n",
      "50%        3.338980\n",
      "75%        3.523140\n",
      "max        3.940260\n",
      "Name: value, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       3.341045\n",
      "std        0.423546\n",
      "min        2.530010\n",
      "25%        3.044258\n",
      "50%        3.297250\n",
      "75%        3.730005\n",
      "max        4.178480\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\dataset_power.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d69e4b4-29ed-4bba-aebc-739a37828218",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    country        date sector    value   timestamp  rounded_value  Treat  \\\n",
      "0     India  01-01-2019  Power  3.33652  1546300800          3.337      0   \n",
      "1     India  02-01-2019  Power  3.37735  1546387200          3.377      0   \n",
      "2     India  03-01-2019  Power  3.41498  1546473600          3.415      0   \n",
      "3     India  04-01-2019  Power  3.44822  1546560000          3.448      0   \n",
      "4     India  05-01-2019  Power  3.42226  1546646400          3.422      0   \n",
      "..      ...         ...    ...      ...         ...            ...    ...   \n",
      "846   India  26-04-2021  Power  3.90782  1619395200          3.908      1   \n",
      "847   India  27-04-2021  Power  3.94942  1619481600          3.949      1   \n",
      "848   India  28-04-2021  Power  3.97784  1619568000          3.978      1   \n",
      "849   India  29-04-2021  Power  3.97340  1619654400          3.973      1   \n",
      "850   India  30-04-2021  Power  3.94838  1619740800          3.948      1   \n",
      "\n",
      "     year  year_2019  year_2020  year_2021  \n",
      "0    2019       True      False      False  \n",
      "1    2019       True      False      False  \n",
      "2    2019       True      False      False  \n",
      "3    2019       True      False      False  \n",
      "4    2019       True      False      False  \n",
      "..    ...        ...        ...        ...  \n",
      "846  2021      False      False       True  \n",
      "847  2021      False      False       True  \n",
      "848  2021      False      False       True  \n",
      "849  2021      False      False       True  \n",
      "850  2021      False      False       True  \n",
      "\n",
      "[851 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\dataset_power.csv\")\n",
    "\n",
    "# Assuming your date variable is named 'date'\n",
    "# Extract the year component from the date variable\n",
    "data['year'] = pd.to_datetime(data['date'], format='%d-%m-%Y').dt.year\n",
    "\n",
    "# Create dummy variables for each year\n",
    "year_dummies = pd.get_dummies(data['year'], prefix='year')\n",
    "\n",
    "# Concatenate the original DataFrame with the year dummy variables\n",
    "data = pd.concat([data, year_dummies], axis=1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7c9945-da4c-42e5-933b-ccd68a80ee47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "rounded_value     0\n",
      "Treat             0\n",
      "year              0\n",
      "year_2019         0\n",
      "year_2020         0\n",
      "year_2021         0\n",
      "Lockdown          0\n",
      "new_date          0\n",
      "Lockdown.1        0\n",
      "Lockdown*Treat    0\n",
      "dtype: int64\n",
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "rounded_value     0\n",
      "Treat             0\n",
      "year              0\n",
      "year_2019         0\n",
      "year_2020         0\n",
      "year_2021         0\n",
      "Lockdown          0\n",
      "new_date          0\n",
      "Lockdown.1        0\n",
      "Lockdown*Treat    0\n",
      "dtype: int64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  value   R-squared:                       0.025\n",
      "Model:                            OLS   Adj. R-squared:                  0.023\n",
      "Method:                 Least Squares   F-statistic:                     10.81\n",
      "Date:                Fri, 29 Mar 2024   Prob (F-statistic):           2.31e-05\n",
      "Time:                        18:52:50   Log-Likelihood:                -336.26\n",
      "No. Observations:                 851   AIC:                             678.5\n",
      "Df Residuals:                     848   BIC:                             692.8\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              2.3913      0.024    100.331      0.000       2.344       2.438\n",
      "Lockdown           0.9112      0.024     38.232      0.000       0.864       0.958\n",
      "Treat              0.7761      0.024     32.563      0.000       0.729       0.823\n",
      "Lockdown*Treat    -0.7040      0.027    -25.715      0.000      -0.758      -0.650\n",
      "==============================================================================\n",
      "Omnibus:                       29.709   Durbin-Watson:                   0.238\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               15.307\n",
      "Skew:                           0.122   Prob(JB):                     0.000474\n",
      "Kurtosis:                       2.390   Cond. No.                     6.06e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.55e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is in a CSV file named 'co2_emissions.csv'\n",
    "df = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\pro_power.csv\")\n",
    "\n",
    "# Check for missing or infinite values in the DataFrame\n",
    "print(df.isnull().sum())  # Check for missing values\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum())  # Check for infinite values\n",
    "\n",
    "# Handle missing or infinite values\n",
    "# For example, you can drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Alternatively, you can replace infinite values with NaN or some other value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN after replacing infinite values\n",
    "\n",
    "# Separate independent variables (X) and dependent variable (y)\n",
    "X = df[['Lockdown', 'Treat', 'Lockdown*Treat']]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "y = df['value']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a463d9b-d978-4aaf-bc73-2448fbfcafdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       0.823440\n",
      "std        0.048295\n",
      "min        0.239000\n",
      "25%        0.821000\n",
      "50%        0.835000\n",
      "75%        0.852000\n",
      "max        0.870000\n",
      "Name: rounded_emissions, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       0.701669\n",
      "std        0.184643\n",
      "min        0.116000\n",
      "25%        0.681750\n",
      "50%        0.790500\n",
      "75%        0.821000\n",
      "max        0.865000\n",
      "Name: rounded_emissions, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\ground_data.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'rounded_emissions'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee3269a2-5b62-49ec-8595-15d77fc3c057",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness and Kurtosis for Pre-COVID Sample:\n",
      "Skewness: -5.290016004950026, Kurtosis: 52.27901790443332\n",
      "\n",
      "Skewness and Kurtosis for COVID Sample:\n",
      "Skewness: -1.6720105151138747, Kurtosis: 1.6947408039050424\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\ground_data.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'rounded_emissions'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_skewness = skew(grouped_data.get_group(0)[co2_column])\n",
    "pre_covid_kurtosis = kurtosis(grouped_data.get_group(0)[co2_column])\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_skewness = skew(grouped_data.get_group(1)[co2_column])\n",
    "covid_kurtosis = kurtosis(grouped_data.get_group(1)[co2_column])\n",
    "\n",
    "# Print skewness and kurtosis for pre-COVID and COVID samples\n",
    "print(\"Skewness and Kurtosis for Pre-COVID Sample:\")\n",
    "print(f\"Skewness: {pre_covid_skewness}, Kurtosis: {pre_covid_kurtosis}\")\n",
    "print(\"\\nSkewness and Kurtosis for COVID Sample:\")\n",
    "print(f\"Skewness: {covid_skewness}, Kurtosis: {covid_kurtosis}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543a616f-b8d4-4adc-8e6a-4c1923f29885",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -2.218078602171282\n",
      "p-value: 0.19974951724852624\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\ground_data.csv\")\n",
    "\n",
    "# Assuming the column containing the time series data is named 'value'\n",
    "# Replace 'value' with the actual column name from your dataset\n",
    "time_series_column = 'rounded_emissions'\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller (ADF) test\n",
    "result = adfuller(data[time_series_column])\n",
    "\n",
    "# Extract and print the test statistic and p-value\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c7bd9a-8029-4a5d-b29c-420767575aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       2.071562\n",
      "std        0.129863\n",
      "min        1.662420\n",
      "25%        1.994740\n",
      "50%        2.079390\n",
      "75%        2.170530\n",
      "max        2.396330\n",
      "Name: value, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       1.832134\n",
      "std        0.411359\n",
      "min        0.507470\n",
      "25%        1.721965\n",
      "50%        1.957115\n",
      "75%        2.103965\n",
      "max        2.313600\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\dataset_industry.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7be7018a-3ddf-4f85-805e-004d62ebeab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness and Kurtosis for Pre-COVID Sample:\n",
      "Skewness: -0.45809918199794813, Kurtosis: 0.006483990670969497\n",
      "\n",
      "Skewness and Kurtosis for COVID Sample:\n",
      "Skewness: -1.655011845567882, Kurtosis: 2.340509886565931\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\dataset_industry.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_skewness = skew(grouped_data.get_group(0)[co2_column])\n",
    "pre_covid_kurtosis = kurtosis(grouped_data.get_group(0)[co2_column])\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_skewness = skew(grouped_data.get_group(1)[co2_column])\n",
    "covid_kurtosis = kurtosis(grouped_data.get_group(1)[co2_column])\n",
    "\n",
    "# Print skewness and kurtosis for pre-COVID and COVID samples\n",
    "print(\"Skewness and Kurtosis for Pre-COVID Sample:\")\n",
    "print(f\"Skewness: {pre_covid_skewness}, Kurtosis: {pre_covid_kurtosis}\")\n",
    "print(\"\\nSkewness and Kurtosis for COVID Sample:\")\n",
    "print(f\"Skewness: {covid_skewness}, Kurtosis: {covid_kurtosis}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7d4d9ce-7ab7-4bf6-9b63-19328ab1ea3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -2.4965481956166773\n",
      "p-value: 0.1163164466399243\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\dataset_industry.csv\")\n",
    "\n",
    "# Assuming the column containing the time series data is named 'value'\n",
    "# Replace 'value' with the actual column name from your dataset\n",
    "time_series_column = 'value'\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller (ADF) test\n",
    "result = adfuller(data[time_series_column])\n",
    "\n",
    "# Extract and print the test statistic and p-value\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21d3a806-3c27-4646-a4c5-b6bf375e8db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness and Kurtosis for Pre-COVID Sample:\n",
      "Skewness: -0.3247065525884265, Kurtosis: -0.5124830783752312\n",
      "\n",
      "Skewness and Kurtosis for COVID Sample:\n",
      "Skewness: 0.10895201164580329, Kurtosis: -0.9181684709968008\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\dataset_power.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_skewness = skew(grouped_data.get_group(0)[co2_column])\n",
    "pre_covid_kurtosis = kurtosis(grouped_data.get_group(0)[co2_column])\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_skewness = skew(grouped_data.get_group(1)[co2_column])\n",
    "covid_kurtosis = kurtosis(grouped_data.get_group(1)[co2_column])\n",
    "\n",
    "# Print skewness and kurtosis for pre-COVID and COVID samples\n",
    "print(\"Skewness and Kurtosis for Pre-COVID Sample:\")\n",
    "print(f\"Skewness: {pre_covid_skewness}, Kurtosis: {pre_covid_kurtosis}\")\n",
    "print(\"\\nSkewness and Kurtosis for COVID Sample:\")\n",
    "print(f\"Skewness: {covid_skewness}, Kurtosis: {covid_kurtosis}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1a020b7-1934-4b44-9fe8-08c4ed13cdbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -1.539779282213034\n",
      "p-value: 0.513749424911319\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\dataset_power.csv\")\n",
    "\n",
    "# Assuming the column containing the time series data is named 'value'\n",
    "# Replace 'value' with the actual column name from your dataset\n",
    "time_series_column = 'value'\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller (ADF) test\n",
    "result = adfuller(data[time_series_column])\n",
    "\n",
    "# Extract and print the test statistic and p-value\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c85a7bd-e1b8-459c-8a70-02c1dda34178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       0.654821\n",
      "std        0.587761\n",
      "min        0.257794\n",
      "25%        0.286477\n",
      "50%        0.340000\n",
      "75%        0.791824\n",
      "max        3.256510\n",
      "Name: value, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       0.498974\n",
      "std        0.444256\n",
      "min        0.255773\n",
      "25%        0.280059\n",
      "50%        0.340722\n",
      "75%        0.415624\n",
      "max        2.302040\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\residential.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aef72b2-9f5f-43b8-8f69-d6890232679b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness and Kurtosis for Pre-COVID Sample:\n",
      "Skewness: 1.8313271295149074, Kurtosis: 3.1392527700448385\n",
      "\n",
      "Skewness and Kurtosis for COVID Sample:\n",
      "Skewness: 2.554373227319871, Kurtosis: 5.475561952811235\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\residential.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_skewness = skew(grouped_data.get_group(0)[co2_column])\n",
    "pre_covid_kurtosis = kurtosis(grouped_data.get_group(0)[co2_column])\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_skewness = skew(grouped_data.get_group(1)[co2_column])\n",
    "covid_kurtosis = kurtosis(grouped_data.get_group(1)[co2_column])\n",
    "\n",
    "# Print skewness and kurtosis for pre-COVID and COVID samples\n",
    "print(\"Skewness and Kurtosis for Pre-COVID Sample:\")\n",
    "print(f\"Skewness: {pre_covid_skewness}, Kurtosis: {pre_covid_kurtosis}\")\n",
    "print(\"\\nSkewness and Kurtosis for COVID Sample:\")\n",
    "print(f\"Skewness: {covid_skewness}, Kurtosis: {covid_kurtosis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6772936a-6cda-4da5-b090-940d2f1e1d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -3.4984614802002665\n",
      "p-value: 0.008026694534343836\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\residential.csv\")\n",
    "\n",
    "# Handle NaN and infinite values\n",
    "data = data.replace([np.inf, -np.inf], np.nan)  # Replace infinite values with NaN\n",
    "data = data.dropna()  # Drop rows with NaN values\n",
    "\n",
    "# Assuming the column containing the time series data is named 'value'\n",
    "# Replace 'value' with the actual column name from your dataset\n",
    "time_series_column = 'value'\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller (ADF) test\n",
    "result = adfuller(data[time_series_column])\n",
    "\n",
    "# Extract and print the test statistic and p-value\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a631872-7a6c-49a9-b5bd-4bb616e13df4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       0.053081\n",
      "std        0.003314\n",
      "min        0.030534\n",
      "25%        0.050663\n",
      "50%        0.053218\n",
      "75%        0.055731\n",
      "max        0.059000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       0.023378\n",
      "std        0.011675\n",
      "min        0.001297\n",
      "25%        0.016190\n",
      "50%        0.025412\n",
      "75%        0.031824\n",
      "max        0.056503\n",
      "Name: Value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\aviation.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'Value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b8c286e-7e7e-4b3d-baed-fd0546dfde54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness and Kurtosis for Pre-COVID Sample:\n",
      "Skewness: -0.811165620604252, Kurtosis: 3.6589587234230274\n",
      "\n",
      "Skewness and Kurtosis for COVID Sample:\n",
      "Skewness: -0.04442667565376433, Kurtosis: -0.05386396813633665\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\aviation.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'Value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_skewness = skew(grouped_data.get_group(0)[co2_column])\n",
    "pre_covid_kurtosis = kurtosis(grouped_data.get_group(0)[co2_column])\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_skewness = skew(grouped_data.get_group(1)[co2_column])\n",
    "covid_kurtosis = kurtosis(grouped_data.get_group(1)[co2_column])\n",
    "\n",
    "# Print skewness and kurtosis for pre-COVID and COVID samples\n",
    "print(\"Skewness and Kurtosis for Pre-COVID Sample:\")\n",
    "print(f\"Skewness: {pre_covid_skewness}, Kurtosis: {pre_covid_kurtosis}\")\n",
    "print(\"\\nSkewness and Kurtosis for COVID Sample:\")\n",
    "print(f\"Skewness: {covid_skewness}, Kurtosis: {covid_kurtosis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c687b57-251b-497d-8e16-5e77b8380cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -1.6962940479679456\n",
      "p-value: 0.43302289931003196\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\aviation.csv\")\n",
    "\n",
    "# Handle NaN and infinite values\n",
    "data = data.replace([np.inf, -np.inf], np.nan)  # Replace infinite values with NaN\n",
    "data = data.dropna()  # Drop rows with NaN values\n",
    "\n",
    "# Assuming the column containing the time series data is named 'value'\n",
    "# Replace 'value' with the actual column name from your dataset\n",
    "time_series_column = 'Value'\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller (ADF) test\n",
    "result = adfuller(data[time_series_column])\n",
    "\n",
    "# Extract and print the test statistic and p-value\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebcb5bed-7341-4a8f-9e25-24a301a44db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "rounded_value     0\n",
      "Treat             0\n",
      "Lockdown          0\n",
      "Lockdown*Treat    0\n",
      "ln_value          0\n",
      "dtype: int64\n",
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "rounded_value     0\n",
      "Treat             0\n",
      "Lockdown          0\n",
      "Lockdown*Treat    0\n",
      "ln_value          0\n",
      "dtype: int64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  value   R-squared:                       0.033\n",
      "Model:                            OLS   Adj. R-squared:                  0.031\n",
      "Method:                 Least Squares   F-statistic:                     14.42\n",
      "Date:                Fri, 12 Apr 2024   Prob (F-statistic):           6.95e-07\n",
      "Time:                        22:37:52   Log-Likelihood:                -646.69\n",
      "No. Observations:                 851   AIC:                             1299.\n",
      "Df Residuals:                     848   BIC:                             1314.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.3551      0.034     10.345      0.000       0.288       0.422\n",
      "Lockdown           0.2997      0.034      8.731      0.000       0.232       0.367\n",
      "Treat             -0.0331      0.034     -0.965      0.335      -0.100       0.034\n",
      "Lockdown*Treat    -0.0885      0.039     -2.245      0.025      -0.166      -0.011\n",
      "==============================================================================\n",
      "Omnibus:                      356.527   Durbin-Watson:                   0.045\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1228.749\n",
      "Skew:                           2.076   Prob(JB):                    1.52e-267\n",
      "Kurtosis:                       7.173   Cond. No.                     6.06e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.55e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is in a CSV file named 'co2_emissions.csv'\n",
    "df = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\residential.csv\")\n",
    "\n",
    "# Check for missing or infinite values in the DataFrame\n",
    "print(df.isnull().sum())  # Check for missing values\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum())  # Check for infinite values\n",
    "\n",
    "# Handle missing or infinite values\n",
    "# For example, you can drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Alternatively, you can replace infinite values with NaN or some other value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN after replacing infinite values\n",
    "\n",
    "# Separate independent variables (X) and dependent variable (y)\n",
    "X = df[['Lockdown', 'Treat', 'Lockdown*Treat']]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "y = df['value']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6256e75e-4796-444f-a59e-79c556418dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "sector.1          0\n",
      "value.1           0\n",
      "Value             0\n",
      "Treat             0\n",
      "Lockdown          0\n",
      "Lockdown*Treat    0\n",
      "ln_value          0\n",
      "dtype: int64\n",
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "sector.1          0\n",
      "value.1           0\n",
      "Value             0\n",
      "Treat             0\n",
      "Lockdown          0\n",
      "Lockdown*Treat    0\n",
      "ln_value          0\n",
      "dtype: int64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Value   R-squared:                       0.870\n",
      "Model:                            OLS   Adj. R-squared:                  0.870\n",
      "Method:                 Least Squares   F-statistic:                     2841.\n",
      "Date:                Sat, 13 Apr 2024   Prob (F-statistic):               0.00\n",
      "Time:                        03:11:31   Log-Likelihood:                 3121.0\n",
      "No. Observations:                 851   AIC:                            -6236.\n",
      "Df Residuals:                     848   BIC:                            -6222.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.0219      0.000     53.417      0.000       0.021       0.023\n",
      "Lockdown           0.0312      0.000     76.035      0.000       0.030       0.032\n",
      "Treat             -0.0176      0.000    -43.023      0.000      -0.018      -0.017\n",
      "Lockdown*Treat    -0.0084      0.000    -17.766      0.000      -0.009      -0.007\n",
      "==============================================================================\n",
      "Omnibus:                      147.525   Durbin-Watson:                   0.203\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              698.686\n",
      "Skew:                           0.708   Prob(JB):                    1.92e-152\n",
      "Kurtosis:                       7.207   Cond. No.                     6.06e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.55e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is in a CSV file named 'co2_emissions.csv'\n",
    "df = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\aviation.csv\")\n",
    "\n",
    "# Check for missing or infinite values in the DataFrame\n",
    "print(df.isnull().sum())  # Check for missing values\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum())  # Check for infinite values\n",
    "\n",
    "# Handle missing or infinite values\n",
    "# For example, you can drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Alternatively, you can replace infinite values with NaN or some other value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN after replacing infinite values\n",
    "\n",
    "# Separate independent variables (X) and dependent variable (y)\n",
    "X = df[['Lockdown', 'Treat', 'Lockdown*Treat']]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "y = df['Value']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26333764-57c5-43fe-a132-85b993f04deb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "rounded_value     0\n",
      "Treat             0\n",
      "Lockdown          0\n",
      "Lockdown*Treat    0\n",
      "ln_value          0\n",
      "dtype: int64\n",
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "rounded_value     0\n",
      "Treat             0\n",
      "Lockdown          0\n",
      "Lockdown*Treat    0\n",
      "ln_value          0\n",
      "dtype: int64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  value   R-squared:                       0.645\n",
      "Model:                            OLS   Adj. R-squared:                  0.644\n",
      "Method:                 Least Squares   F-statistic:                     770.3\n",
      "Date:                Sat, 13 Apr 2024   Prob (F-statistic):          2.02e-191\n",
      "Time:                        03:00:23   Log-Likelihood:                 183.12\n",
      "No. Observations:                 851   AIC:                            -360.2\n",
      "Df Residuals:                     848   BIC:                            -346.0\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              1.0810      0.013     83.502      0.000       1.056       1.106\n",
      "Lockdown           0.9906      0.013     76.514      0.000       0.965       1.016\n",
      "Treat             -0.0017      0.013     -0.134      0.894      -0.027       0.024\n",
      "Lockdown*Treat    -0.0922      0.015     -6.200      0.000      -0.121      -0.063\n",
      "==============================================================================\n",
      "Omnibus:                       54.140   Durbin-Watson:                   0.293\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              214.280\n",
      "Skew:                           0.075   Prob(JB):                     2.95e-47\n",
      "Kurtosis:                       5.454   Cond. No.                     6.06e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.55e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is in a CSV file named 'co2_emissions.csv'\n",
    "df = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\dataset_industry.csv\")\n",
    "\n",
    "# Check for missing or infinite values in the DataFrame\n",
    "print(df.isnull().sum())  # Check for missing values\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum())  # Check for infinite values\n",
    "\n",
    "# Handle missing or infinite values\n",
    "# For example, you can drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Alternatively, you can replace infinite values with NaN or some other value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN after replacing infinite values\n",
    "\n",
    "# Separate independent variables (X) and dependent variable (y)\n",
    "X = df[['Lockdown', 'Treat', 'Lockdown*Treat']]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "y = df['value']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3ac2411-5061-408c-90ba-368d9e4a1d44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country              0\n",
      "date                 0\n",
      "sector               0\n",
      "emission             0\n",
      "abc                  0\n",
      "rounded_emissions    0\n",
      "Treat                0\n",
      "Lockdown             0\n",
      "Lockdown*Treat       0\n",
      "ln_value             0\n",
      "month                0\n",
      "year                 0\n",
      "dtype: int64\n",
      "Country              0\n",
      "date                 0\n",
      "sector               0\n",
      "emission             0\n",
      "abc                  0\n",
      "rounded_emissions    0\n",
      "Treat                0\n",
      "Lockdown             0\n",
      "Lockdown*Treat       0\n",
      "ln_value             0\n",
      "month                0\n",
      "year                 0\n",
      "dtype: int64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               emission   R-squared:                       0.581\n",
      "Model:                            OLS   Adj. R-squared:                  0.580\n",
      "Method:                 Least Squares   F-statistic:                     588.5\n",
      "Date:                Sat, 13 Apr 2024   Prob (F-statistic):          5.14e-161\n",
      "Time:                        03:07:24   Log-Likelihood:                 788.81\n",
      "No. Observations:                 851   AIC:                            -1572.\n",
      "Df Residuals:                     848   BIC:                            -1557.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.4198      0.006     66.064      0.000       0.407       0.432\n",
      "Lockdown           0.4037      0.006     63.544      0.000       0.391       0.416\n",
      "Treat             -0.0234      0.006     -3.683      0.000      -0.036      -0.011\n",
      "Lockdown*Treat    -0.0394      0.007     -5.401      0.000      -0.054      -0.025\n",
      "==============================================================================\n",
      "Omnibus:                      489.862   Durbin-Watson:                   0.976\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5751.021\n",
      "Skew:                          -2.393   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.802   Cond. No.                     6.06e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.55e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is in a CSV file named 'co2_emissions.csv'\n",
    "df = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\ground_data.csv\")\n",
    "\n",
    "# Check for missing or infinite values in the DataFrame\n",
    "print(df.isnull().sum())  # Check for missing values\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum())  # Check for infinite values\n",
    "\n",
    "# Handle missing or infinite values\n",
    "# For example, you can drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Alternatively, you can replace infinite values with NaN or some other value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN after replacing infinite values\n",
    "\n",
    "# Separate independent variables (X) and dependent variable (y)\n",
    "X = df[['Lockdown', 'Treat', 'Lockdown*Treat']]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "y = df['emission']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "876c33fa-752b-4498-a18f-3b16309d0da4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Test Results for aviation_Value sector after second difference:\n",
      "Test Statistic: -12.607626190657568\n",
      "P-value: 1.682277434960888e-23\n",
      "Critical Values:\n",
      "\t1%: -3.438262743153934\n",
      "\t5%: -2.8650327208928976\n",
      "\t10%: -2.5686298171529347\n",
      "\n",
      "ADF Test Results for power_value sector after second difference:\n",
      "Test Statistic: -11.92071929988393\n",
      "P-value: 5.039914076595949e-22\n",
      "Critical Values:\n",
      "\t1%: -3.4382819390603068\n",
      "\t5%: -2.865041182894659\n",
      "\t10%: -2.568634324805645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# augmented dickey fuller test:5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Read the data from the CSV file\n",
    "emissions_data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\adf.csv\")\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "emissions_data['date'] = pd.to_datetime(emissions_data['date'])\n",
    "\n",
    "# Take the natural logarithm of the CO2 emissions data for each sector\n",
    "emissions_data_ln = emissions_data.drop(columns=['date']).apply(lambda x: x.apply(lambda y: y if y <= 0 else np.log(y)))\n",
    "\n",
    "# Take the second difference of the natural logarithm of the data\n",
    "emissions_data_ln_diff2 = emissions_data_ln.diff().diff()\n",
    "\n",
    "# Perform ADF test on each sector's data\n",
    "for sector in emissions_data_ln_diff2.columns:\n",
    "    # Perform ADF test\n",
    "    result = adfuller(emissions_data_ln_diff2[sector].dropna())  # Drop NA values\n",
    "    \n",
    "    # Extract results\n",
    "    print(f\"ADF Test Results for {sector} sector after second difference:\")\n",
    "    print(f\"Test Statistic: {result[0]}\")\n",
    "    print(f\"P-value: {result[1]}\")\n",
    "    print(\"Critical Values:\")\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "    print(\"\")\n",
    "\n",
    "# The null hypothesis of the ADF test is that the time series has a unit root (i.e., it is non-stationary).\n",
    "# If the p-value is less than the significance level (e.g., 0.05), we reject the null hypothesis,\n",
    "# indicating that the time series is stationary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6a161ce-e8b1-42d0-b894-659349507998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Test Results for power sector after first difference:\n",
      "Test Statistic: -10.196384662898838\n",
      "P-value: 6.130755016342405e-18\n",
      "Critical Values:\n",
      "\t1%: -3.4382531800005944\n",
      "\t5%: -2.8650285052126057\n",
      "\t10%: -2.5686275714907825\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Read the data from the CSV file\n",
    "emissions_data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\adf.csv\")\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "emissions_data['date'] = pd.to_datetime(emissions_data['date'])\n",
    "\n",
    "# Take the natural logarithm of the CO2 emissions data for each sector\n",
    "emissions_data_ln = emissions_data.drop(columns=['date']).apply(lambda x: x.apply(lambda y: y if y <= 0 else np.log(y)))\n",
    "\n",
    "# Take the first difference of the natural logarithm of the data\n",
    "emissions_data_ln_diff1 = emissions_data_ln.diff()\n",
    "\n",
    "# Perform ADF test\n",
    "result = adfuller(emissions_data_ln_diff1['power_value'].dropna())  # Drop NA values\n",
    "\n",
    "# Extract results\n",
    "print(\"ADF Test Results for power sector after first difference:\")\n",
    "print(f\"Test Statistic: {result[0]}\")\n",
    "print(f\"P-value: {result[1]}\")\n",
    "print(\"Critical Values:\")\n",
    "for key, value in result[4].items():\n",
    "    print(f\"\\t{key}: {value}\")\n",
    "\n",
    "# The null hypothesis of the ADF test is that the time series has a unit root (i.e., it is non-stationary).\n",
    "# If the p-value is less than the significance level (e.g., 0.05), we reject the null hypothesis,\n",
    "# indicating that the time series is stationary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1acbb4b2-d2b7-4d9a-acbf-3b989caeb38b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Test Results for aviation sector after first difference:\n",
      "Test Statistic: -4.947794042847262\n",
      "P-value: 2.8125455312399724e-05\n",
      "Critical Values:\n",
      "\t1%: -3.438262743153934\n",
      "\t5%: -2.8650327208928976\n",
      "\t10%: -2.5686298171529347\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Read the data from the CSV file\n",
    "emissions_data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\adf.csv\")\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "emissions_data['date'] = pd.to_datetime(emissions_data['date'])\n",
    "\n",
    "# Take the natural logarithm of the CO2 emissions data for each sector\n",
    "emissions_data_ln = emissions_data.drop(columns=['date']).apply(lambda x: x.apply(lambda y: y if y <= 0 else np.log(y)))\n",
    "\n",
    "# Take the first difference of the natural logarithm of the data\n",
    "emissions_data_ln_diff1 = emissions_data_ln.diff()\n",
    "\n",
    "# Perform ADF test\n",
    "result = adfuller(emissions_data_ln_diff1['aviation_Value'].dropna())  # Drop NA values\n",
    "\n",
    "# Extract results\n",
    "print(\"ADF Test Results for aviation sector after first difference:\")\n",
    "print(f\"Test Statistic: {result[0]}\")\n",
    "print(f\"P-value: {result[1]}\")\n",
    "print(\"Critical Values:\")\n",
    "for key, value in result[4].items():\n",
    "    print(f\"\\t{key}: {value}\")\n",
    "\n",
    "# The null hypothesis of the ADF test is that the time series has a unit root (i.e., it is non-stationary).\n",
    "# If the p-value is less than the significance level (e.g., 0.05), we reject the null hypothesis,\n",
    "# indicating that the time series is stationary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b79c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       6.905431\n",
      "std        0.766338\n",
      "min        5.390165\n",
      "25%        6.339276\n",
      "50%        6.880398\n",
      "75%        7.284676\n",
      "max        9.778580\n",
      "Name: sum_of_emission, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       6.397204\n",
      "std        1.053378\n",
      "min        3.693557\n",
      "25%        5.719619\n",
      "50%        6.383232\n",
      "75%        7.101550\n",
      "max        9.077752\n",
      "Name: sum_of_emission, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\expert_output_file.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'sum_of_emission'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edb9a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness and Kurtosis for Pre-COVID Sample:\n",
      "Skewness: 0.6644953362565132, Kurtosis: 0.7700417321032695\n",
      "\n",
      "Skewness and Kurtosis for COVID Sample:\n",
      "Skewness: -0.008120382189233095, Kurtosis: 0.08367922553353058\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\expert_output_file.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'sum_of_emission'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_skewness = skew(grouped_data.get_group(0)[co2_column])\n",
    "pre_covid_kurtosis = kurtosis(grouped_data.get_group(0)[co2_column])\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_skewness = skew(grouped_data.get_group(1)[co2_column])\n",
    "covid_kurtosis = kurtosis(grouped_data.get_group(1)[co2_column])\n",
    "\n",
    "# Print skewness and kurtosis for pre-COVID and COVID samples\n",
    "print(\"Skewness and Kurtosis for Pre-COVID Sample:\")\n",
    "print(f\"Skewness: {pre_covid_skewness}, Kurtosis: {pre_covid_kurtosis}\")\n",
    "print(\"\\nSkewness and Kurtosis for COVID Sample:\")\n",
    "print(f\"Skewness: {covid_skewness}, Kurtosis: {covid_kurtosis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "237c6766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -2.3026998748860326\n",
      "p-value: 0.17109868667607842\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\expert_output_file.csv\")\n",
    "\n",
    "# Handle NaN and infinite values\n",
    "data = data.replace([np.inf, -np.inf], np.nan)  # Replace infinite values with NaN\n",
    "data = data.dropna()  # Drop rows with NaN values\n",
    "\n",
    "# Assuming the column containing the time series data is named 'value'\n",
    "# Replace 'value' with the actual column name from your dataset\n",
    "time_series_column = 'sum_of_emission'\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller (ADF) test\n",
    "result = adfuller(data[time_series_column])\n",
    "\n",
    "# Extract and print the test statistic and p-value\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e79d21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean                0\n",
      "Treat               0\n",
      "Lockdown            0\n",
      "Treat*Lockdown      0\n",
      "date                0\n",
      "sum_of_emission     0\n",
      "rounded_emission    0\n",
      "ln_value            0\n",
      "month               0\n",
      "year                0\n",
      "dtype: int64\n",
      "Mean                0\n",
      "Treat               0\n",
      "Lockdown            0\n",
      "Treat*Lockdown      0\n",
      "date                0\n",
      "sum_of_emission     0\n",
      "rounded_emission    0\n",
      "ln_value            0\n",
      "month               0\n",
      "year                0\n",
      "dtype: int64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        sum_of_emission   R-squared:                       0.487\n",
      "Model:                            OLS   Adj. R-squared:                  0.485\n",
      "Method:                 Least Squares   F-statistic:                     201.2\n",
      "Date:                Fri, 12 Apr 2024   Prob (F-statistic):          3.36e-121\n",
      "Time:                        18:32:23   Log-Likelihood:                -883.60\n",
      "No. Observations:                 851   AIC:                             1777.\n",
      "Df Residuals:                     846   BIC:                             1801.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              3.4130      0.108     31.587      0.000       3.201       3.625\n",
      "Lockdown           2.5436      0.054     46.975      0.000       2.437       2.650\n",
      "Treat             -0.2410      0.095     -2.543      0.011      -0.427      -0.055\n",
      "Treat*Lockdown    -1.1103      0.054    -20.685      0.000      -1.216      -1.005\n",
      "month             -0.0229      0.009     -2.628      0.009      -0.040      -0.006\n",
      "year               0.9483      0.077     12.293      0.000       0.797       1.100\n",
      "==============================================================================\n",
      "Omnibus:                      180.016   Durbin-Watson:                   0.232\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              465.416\n",
      "Skew:                           1.090   Prob(JB):                    8.63e-102\n",
      "Kurtosis:                       5.894   Cond. No.                     3.12e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.5e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is in a CSV file named 'co2_emissions.csv'\n",
    "df = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\expert_output_file.csv\")\n",
    "\n",
    "# Check for missing or infinite values in the DataFrame\n",
    "print(df.isnull().sum())  # Check for missing values\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum())  # Check for infinite values\n",
    "\n",
    "# Handle missing or infinite values\n",
    "# For example, you can drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Alternatively, you can replace infinite values with NaN or some other value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN after replacing infinite values\n",
    "\n",
    "# Separate independent variables (X) and dependent variable (y)\n",
    "X = df[['Lockdown', 'Treat', 'Treat*Lockdown','month','year']]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "y = df['sum_of_emission']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##..............For Spain..............####:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1c694905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       0.234521\n",
      "std        0.054275\n",
      "min        0.098925\n",
      "25%        0.181963\n",
      "50%        0.262235\n",
      "75%        0.266759\n",
      "max        0.305978\n",
      "Name: value, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       0.211421\n",
      "std        0.068629\n",
      "min        0.063176\n",
      "25%        0.147733\n",
      "50%        0.225185\n",
      "75%        0.275015\n",
      "max        0.302583\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\ground_spain.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "48d3fbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness and Kurtosis for Pre-COVID Sample:\n",
      "Skewness: -1.0171067898833228, Kurtosis: -0.38337682604646695\n",
      "\n",
      "Skewness and Kurtosis for COVID Sample:\n",
      "Skewness: -0.4502497138149638, Kurtosis: -1.1386112626095564\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\ground_spain.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_skewness = skew(grouped_data.get_group(0)[co2_column])\n",
    "pre_covid_kurtosis = kurtosis(grouped_data.get_group(0)[co2_column])\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_skewness = skew(grouped_data.get_group(1)[co2_column])\n",
    "covid_kurtosis = kurtosis(grouped_data.get_group(1)[co2_column])\n",
    "\n",
    "# Print skewness and kurtosis for pre-COVID and COVID samples\n",
    "print(\"Skewness and Kurtosis for Pre-COVID Sample:\")\n",
    "print(f\"Skewness: {pre_covid_skewness}, Kurtosis: {pre_covid_kurtosis}\")\n",
    "print(\"\\nSkewness and Kurtosis for COVID Sample:\")\n",
    "print(f\"Skewness: {covid_skewness}, Kurtosis: {covid_kurtosis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4c619ccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDataError",
     "evalue": "exog contains inf or nans",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingDataError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m time_series_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Perform the Augmented Dickey-Fuller (ADF) test\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m result \u001b[38;5;241m=\u001b[39m adfuller(data[time_series_column])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Extract and print the test statistic and p-value\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADF Statistic:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mD:\\Conda\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:324\u001b[0m, in \u001b[0;36madfuller\u001b[1;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# 1 for level\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# search for lag length with smallest information criteria\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# Note: use the same number of observations to have comparable IC\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# aic and bic: smaller is better\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m regresults:\n\u001b[1;32m--> 324\u001b[0m     icbest, bestlag \u001b[38;5;241m=\u001b[39m _autolag(\n\u001b[0;32m    325\u001b[0m         OLS, xdshort, fullRHS, startlag, maxlag, autolag\n\u001b[0;32m    326\u001b[0m     )\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    328\u001b[0m     icbest, bestlag, alres \u001b[38;5;241m=\u001b[39m _autolag(\n\u001b[0;32m    329\u001b[0m         OLS,\n\u001b[0;32m    330\u001b[0m         xdshort,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    335\u001b[0m         regresults\u001b[38;5;241m=\u001b[39mregresults,\n\u001b[0;32m    336\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Conda\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:130\u001b[0m, in \u001b[0;36m_autolag\u001b[1;34m(mod, endog, exog, startlag, maxlag, method, modargs, fitargs, regresults)\u001b[0m\n\u001b[0;32m    128\u001b[0m method \u001b[38;5;241m=\u001b[39m method\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(startlag, startlag \u001b[38;5;241m+\u001b[39m maxlag \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 130\u001b[0m     mod_instance \u001b[38;5;241m=\u001b[39m mod(endog, exog[:, :lag], \u001b[38;5;241m*\u001b[39mmodargs)\n\u001b[0;32m    131\u001b[0m     results[lag] \u001b[38;5;241m=\u001b[39m mod_instance\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maic\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mD:\\Conda\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:922\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    919\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    920\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn exception will be raised in the next version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    921\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28msuper\u001b[39m(OLS, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    923\u001b[0m                           hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys:\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Conda\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:748\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28msuper\u001b[39m(WLS, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    749\u001b[0m                           weights\u001b[38;5;241m=\u001b[39mweights, hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    750\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    751\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n",
      "File \u001b[1;32mD:\\Conda\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:202\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28msuper\u001b[39m(RegressionModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog: Float64Array \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_attr\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwendog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mD:\\Conda\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32mD:\\Conda\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m     96\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32mD:\\Conda\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mD:\\Conda\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass(endog, exog\u001b[38;5;241m=\u001b[39mexog, missing\u001b[38;5;241m=\u001b[39mmissing, hasconst\u001b[38;5;241m=\u001b[39mhasconst,\n\u001b[0;32m    676\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Conda\\Lib\\site-packages\\statsmodels\\base\\data.py:88\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_constant(hasconst)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity()\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mD:\\Conda\\Lib\\site-packages\\statsmodels\\base\\data.py:134\u001b[0m, in \u001b[0;36mModelData._handle_constant\u001b[1;34m(self, hasconst)\u001b[0m\n\u001b[0;32m    132\u001b[0m exog_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(exog_max)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingDataError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexog contains inf or nans\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    135\u001b[0m exog_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    136\u001b[0m const_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(exog_max \u001b[38;5;241m==\u001b[39m exog_min)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[1;31mMissingDataError\u001b[0m: exog contains inf or nans"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\ground_spain.csv\")\n",
    "\n",
    "# Assuming the column containing the time series data is named 'value'\n",
    "# Replace 'value' with the actual column name from your dataset\n",
    "time_series_column = 'value'\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller (ADF) test\n",
    "result = adfuller(data[time_series_column])\n",
    "\n",
    "# Extract and print the test statistic and p-value\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec9f1b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country           1035\n",
      "date              1035\n",
      "sector            1035\n",
      "value             1035\n",
      "timestamp         1035\n",
      "Treat             1035\n",
      "Lockdown          1035\n",
      "Treat*Lockdown    1035\n",
      "dtype: int64\n",
      "country           1035\n",
      "date              1035\n",
      "sector            1035\n",
      "value             1035\n",
      "timestamp         1035\n",
      "Treat             1035\n",
      "Lockdown          1035\n",
      "Treat*Lockdown    1035\n",
      "dtype: int64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  value   R-squared:                       0.299\n",
      "Model:                            OLS   Adj. R-squared:                  0.298\n",
      "Method:                 Least Squares   F-statistic:                     181.1\n",
      "Date:                Sun, 07 Apr 2024   Prob (F-statistic):           3.20e-66\n",
      "Time:                        18:40:44   Log-Likelihood:                 1298.2\n",
      "No. Observations:                 851   AIC:                            -2590.\n",
      "Df Residuals:                     848   BIC:                            -2576.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.1224      0.003     40.546      0.000       0.117       0.128\n",
      "Lockdown           0.1121      0.003     37.121      0.000       0.106       0.118\n",
      "Treat              0.0063      0.003      2.088      0.037       0.000       0.012\n",
      "Treat*Lockdown    -0.0040      0.004     -1.104      0.270      -0.011       0.003\n",
      "==============================================================================\n",
      "Omnibus:                       88.020   Durbin-Watson:                   1.314\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              102.171\n",
      "Skew:                          -0.815   Prob(JB):                     6.51e-23\n",
      "Kurtosis:                       2.528   Cond. No.                     8.22e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.89e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is in a CSV file named 'co2_emissions.csv'\n",
    "df = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\ground_spain.csv\")\n",
    "\n",
    "# Check for missing or infinite values in the DataFrame\n",
    "print(df.isnull().sum())  # Check for missing values\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum())  # Check for infinite values\n",
    "\n",
    "# Handle missing or infinite values\n",
    "# For example, you can drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Alternatively, you can replace infinite values with NaN or some other value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN after replacing infinite values\n",
    "\n",
    "# Separate independent variables (X) and dependent variable (y)\n",
    "X = df[['Lockdown', 'Treat', 'Treat*Lockdown']]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "y = df['value']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de63f7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       0.079442\n",
      "std        0.013311\n",
      "min        0.046350\n",
      "25%        0.067986\n",
      "50%        0.079786\n",
      "75%        0.091387\n",
      "max        0.104998\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       0.022934\n",
      "std        0.014625\n",
      "min        0.003057\n",
      "25%        0.013519\n",
      "50%        0.020714\n",
      "75%        0.030537\n",
      "max        0.078255\n",
      "Name: Value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\aviation.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'Value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "702f306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness and Kurtosis for Pre-COVID Sample:\n",
      "Skewness: -0.07589109571299586, Kurtosis: -1.1433291337881022\n",
      "\n",
      "Skewness and Kurtosis for COVID Sample:\n",
      "Skewness: 1.074876775201752, Kurtosis: 1.5677680263812226\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\aviation.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'Value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_skewness = skew(grouped_data.get_group(0)[co2_column])\n",
    "pre_covid_kurtosis = kurtosis(grouped_data.get_group(0)[co2_column])\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_skewness = skew(grouped_data.get_group(1)[co2_column])\n",
    "covid_kurtosis = kurtosis(grouped_data.get_group(1)[co2_column])\n",
    "\n",
    "# Print skewness and kurtosis for pre-COVID and COVID samples\n",
    "print(\"Skewness and Kurtosis for Pre-COVID Sample:\")\n",
    "print(f\"Skewness: {pre_covid_skewness}, Kurtosis: {pre_covid_kurtosis}\")\n",
    "print(\"\\nSkewness and Kurtosis for COVID Sample:\")\n",
    "print(f\"Skewness: {covid_skewness}, Kurtosis: {covid_kurtosis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3304de24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -1.2701352603236702\n",
      "p-value: 0.6427223410789012\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\aviation.csv\")\n",
    "\n",
    "# Assuming the column containing the time series data is named 'value'\n",
    "# Replace 'value' with the actual column name from your dataset\n",
    "time_series_column = 'Value'\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller (ADF) test\n",
    "result = adfuller(data[time_series_column])\n",
    "\n",
    "# Extract and print the test statistic and p-value\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ba8d1759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "sector.1          0\n",
      "value.1           0\n",
      "Value             0\n",
      "Treat             0\n",
      "Lockdown          0\n",
      "Treat*Lockdown    0\n",
      "dtype: int64\n",
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "sector.1          0\n",
      "value.1           0\n",
      "Value             0\n",
      "Treat             0\n",
      "Lockdown          0\n",
      "Treat*Lockdown    0\n",
      "dtype: int64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Value   R-squared:                       0.833\n",
      "Model:                            OLS   Adj. R-squared:                  0.833\n",
      "Method:                 Least Squares   F-statistic:                     2114.\n",
      "Date:                Sun, 07 Apr 2024   Prob (F-statistic):               0.00\n",
      "Time:                        18:55:13   Log-Likelihood:                 2495.9\n",
      "No. Observations:                 851   AIC:                            -4986.\n",
      "Df Residuals:                     848   BIC:                            -4972.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.0375      0.001     50.752      0.000       0.036       0.039\n",
      "Lockdown           0.0419      0.001     56.725      0.000       0.040       0.043\n",
      "Treat             -0.0283      0.001    -38.354      0.000      -0.030      -0.027\n",
      "Treat*Lockdown    -0.0239      0.001    -26.729      0.000      -0.026      -0.022\n",
      "==============================================================================\n",
      "Omnibus:                      118.602   Durbin-Watson:                   0.172\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              205.657\n",
      "Skew:                           0.878   Prob(JB):                     2.20e-45\n",
      "Kurtosis:                       4.649   Cond. No.                     8.22e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.89e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is in a CSV file named 'co2_emissions.csv'\n",
    "df = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\aviation.csv\")\n",
    "\n",
    "# Check for missing or infinite values in the DataFrame\n",
    "print(df.isnull().sum())  # Check for missing values\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum())  # Check for infinite values\n",
    "\n",
    "# Handle missing or infinite values\n",
    "# For example, you can drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Alternatively, you can replace infinite values with NaN or some other value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN after replacing infinite values\n",
    "\n",
    "# Separate independent variables (X) and dependent variable (y)\n",
    "X = df[['Lockdown', 'Treat', 'Treat*Lockdown']]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "y = df['Value']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f351cd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       0.170315\n",
      "std        0.038773\n",
      "min        0.069125\n",
      "25%        0.143903\n",
      "50%        0.168165\n",
      "75%        0.201071\n",
      "max        0.264787\n",
      "Name: value, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       0.154810\n",
      "std        0.040725\n",
      "min        0.064538\n",
      "25%        0.123676\n",
      "50%        0.151520\n",
      "75%        0.184381\n",
      "max        0.259077\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\industry.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e3d804be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness and Kurtosis for Pre-COVID Sample:\n",
      "Skewness: -0.05727939458933124, Kurtosis: -0.5869252705842452\n",
      "\n",
      "Skewness and Kurtosis for COVID Sample:\n",
      "Skewness: 0.2662796425905379, Kurtosis: -0.61479440047323\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\industry.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_skewness = skew(grouped_data.get_group(0)[co2_column])\n",
    "pre_covid_kurtosis = kurtosis(grouped_data.get_group(0)[co2_column])\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_skewness = skew(grouped_data.get_group(1)[co2_column])\n",
    "covid_kurtosis = kurtosis(grouped_data.get_group(1)[co2_column])\n",
    "\n",
    "# Print skewness and kurtosis for pre-COVID and COVID samples\n",
    "print(\"Skewness and Kurtosis for Pre-COVID Sample:\")\n",
    "print(f\"Skewness: {pre_covid_skewness}, Kurtosis: {pre_covid_kurtosis}\")\n",
    "print(\"\\nSkewness and Kurtosis for COVID Sample:\")\n",
    "print(f\"Skewness: {covid_skewness}, Kurtosis: {covid_kurtosis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5c2dc883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -7.092346822490416\n",
      "p-value: 4.3772318419757684e-10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\industry.csv\")\n",
    "\n",
    "# Assuming the column containing the time series data is named 'value'\n",
    "# Replace 'value' with the actual column name from your dataset\n",
    "time_series_column = 'value'\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller (ADF) test\n",
    "result = adfuller(data[time_series_column])\n",
    "\n",
    "# Extract and print the test statistic and p-value\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "16148035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country              0\n",
      "date                 0\n",
      "sector               0\n",
      "value                0\n",
      "timestamp            0\n",
      "Treat             1035\n",
      "Lockdown          1035\n",
      "Treat*Lockdown    1035\n",
      "dtype: int64\n",
      "country              0\n",
      "date                 0\n",
      "sector               0\n",
      "value                0\n",
      "timestamp            0\n",
      "Treat             1035\n",
      "Lockdown          1035\n",
      "Treat*Lockdown    1035\n",
      "dtype: int64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  value   R-squared:                       0.093\n",
      "Model:                            OLS   Adj. R-squared:                  0.091\n",
      "Method:                 Least Squares   F-statistic:                     43.71\n",
      "Date:                Sun, 07 Apr 2024   Prob (F-statistic):           8.60e-19\n",
      "Time:                        19:11:19   Log-Likelihood:                 1563.7\n",
      "No. Observations:                 851   AIC:                            -3121.\n",
      "Df Residuals:                     848   BIC:                            -3107.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.1097      0.002     49.617      0.000       0.105       0.114\n",
      "Lockdown           0.0606      0.002     27.434      0.000       0.056       0.065\n",
      "Treat              0.0205      0.002      9.291      0.000       0.016       0.025\n",
      "Treat*Lockdown    -0.0285      0.003    -10.642      0.000      -0.034      -0.023\n",
      "==============================================================================\n",
      "Omnibus:                       21.542   Durbin-Watson:                   0.717\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               11.210\n",
      "Skew:                           0.007   Prob(JB):                      0.00368\n",
      "Kurtosis:                       2.438   Cond. No.                     8.22e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.89e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is in a CSV file named 'co2_emissions.csv'\n",
    "df = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\industry.csv\")\n",
    "\n",
    "# Check for missing or infinite values in the DataFrame\n",
    "print(df.isnull().sum())  # Check for missing values\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum())  # Check for infinite values\n",
    "\n",
    "# Handle missing or infinite values\n",
    "# For example, you can drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Alternatively, you can replace infinite values with NaN or some other value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN after replacing infinite values\n",
    "\n",
    "# Separate independent variables (X) and dependent variable (y)\n",
    "X = df[['Lockdown', 'Treat', 'Treat*Lockdown']]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "y = df['value']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "32c4df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "Treat             0\n",
      "Lockdown          0\n",
      "Treat*Lockdown    0\n",
      "ln_value          0\n",
      "dtype: int64\n",
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "Treat             0\n",
      "Lockdown          0\n",
      "Treat*Lockdown    0\n",
      "ln_value          0\n",
      "dtype: int64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  value   R-squared:                       0.225\n",
      "Model:                            OLS   Adj. R-squared:                  0.224\n",
      "Method:                 Least Squares   F-statistic:                     123.3\n",
      "Date:                Sun, 07 Apr 2024   Prob (F-statistic):           9.65e-48\n",
      "Time:                        19:28:01   Log-Likelihood:                 1646.6\n",
      "No. Observations:                 851   AIC:                            -3287.\n",
      "Df Residuals:                     848   BIC:                            -3273.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.0928      0.002     46.257      0.000       0.089       0.097\n",
      "Lockdown           0.0564      0.002     28.104      0.000       0.052       0.060\n",
      "Treat              0.0035      0.002      1.722      0.085      -0.000       0.007\n",
      "Treat*Lockdown    -0.0329      0.002    -13.563      0.000      -0.038      -0.028\n",
      "==============================================================================\n",
      "Omnibus:                       27.736   Durbin-Watson:                   0.563\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               13.255\n",
      "Skew:                           0.000   Prob(JB):                      0.00132\n",
      "Kurtosis:                       2.389   Cond. No.                     8.22e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.89e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is in a CSV file named 'co2_emissions.csv'\n",
    "df = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\power.csv\")\n",
    "\n",
    "# Check for missing or infinite values in the DataFrame\n",
    "print(df.isnull().sum())  # Check for missing values\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum())  # Check for infinite values\n",
    "\n",
    "# Handle missing or infinite values\n",
    "# For example, you can drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Alternatively, you can replace infinite values with NaN or some other value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN after replacing infinite values\n",
    "\n",
    "# Separate independent variables (X) and dependent variable (y)\n",
    "X = df[['Lockdown', 'Treat', 'Treat*Lockdown']]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "y = df['value']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "599cc21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       0.149113\n",
      "std        0.035048\n",
      "min        0.055296\n",
      "25%        0.124492\n",
      "50%        0.150247\n",
      "75%        0.174825\n",
      "max        0.239117\n",
      "Name: value, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       0.114123\n",
      "std        0.036322\n",
      "min        0.048601\n",
      "25%        0.083796\n",
      "50%        0.106631\n",
      "75%        0.144755\n",
      "max        0.195065\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\power.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ae9b1767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness and Kurtosis for Pre-COVID Sample:\n",
      "Skewness: -0.14834499626524764, Kurtosis: -0.37893537575217273\n",
      "\n",
      "Skewness and Kurtosis for COVID Sample:\n",
      "Skewness: 0.37610892761724907, Kurtosis: -0.9474487311029258\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\power.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_skewness = skew(grouped_data.get_group(0)[co2_column])\n",
    "pre_covid_kurtosis = kurtosis(grouped_data.get_group(0)[co2_column])\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_skewness = skew(grouped_data.get_group(1)[co2_column])\n",
    "covid_kurtosis = kurtosis(grouped_data.get_group(1)[co2_column])\n",
    "\n",
    "# Print skewness and kurtosis for pre-COVID and COVID samples\n",
    "print(\"Skewness and Kurtosis for Pre-COVID Sample:\")\n",
    "print(f\"Skewness: {pre_covid_skewness}, Kurtosis: {pre_covid_kurtosis}\")\n",
    "print(\"\\nSkewness and Kurtosis for COVID Sample:\")\n",
    "print(f\"Skewness: {covid_skewness}, Kurtosis: {covid_kurtosis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b364dbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -3.0324875243222533\n",
      "p-value: 0.03196985343285483\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\power.csv\")\n",
    "\n",
    "# Assuming the column containing the time series data is named 'value'\n",
    "# Replace 'value' with the actual column name from your dataset\n",
    "time_series_column = 'value'\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller (ADF) test\n",
    "result = adfuller(data[time_series_column])\n",
    "\n",
    "# Extract and print the test statistic and p-value\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe52ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "Treat             0\n",
      "Lockdown          0\n",
      "Treat*Lockdown    0\n",
      "dtype: int64\n",
      "country           0\n",
      "date              0\n",
      "sector            0\n",
      "value             0\n",
      "timestamp         0\n",
      "Treat             0\n",
      "Lockdown          0\n",
      "Treat*Lockdown    0\n",
      "dtype: int64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  value   R-squared:                       0.018\n",
      "Model:                            OLS   Adj. R-squared:                  0.015\n",
      "Method:                 Least Squares   F-statistic:                     7.573\n",
      "Date:                Fri, 12 Apr 2024   Prob (F-statistic):           0.000550\n",
      "Time:                        18:56:21   Log-Likelihood:                 1575.2\n",
      "No. Observations:                 851   AIC:                            -3144.\n",
      "Df Residuals:                     848   BIC:                            -3130.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.0720      0.002     32.994      0.000       0.068       0.076\n",
      "Lockdown           0.0345      0.002     15.825      0.000       0.030       0.039\n",
      "Treat              0.0189      0.002      8.657      0.000       0.015       0.023\n",
      "Treat*Lockdown    -0.0186      0.003     -7.027      0.000      -0.024      -0.013\n",
      "==============================================================================\n",
      "Omnibus:                      122.283   Durbin-Watson:                   0.052\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               43.424\n",
      "Skew:                           0.324   Prob(JB):                     3.72e-10\n",
      "Kurtosis:                       2.104   Cond. No.                     8.22e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.89e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is in a CSV file named 'co2_emissions.csv'\n",
    "df = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\residential.csv\")\n",
    "\n",
    "# Check for missing or infinite values in the DataFrame\n",
    "print(df.isnull().sum())  # Check for missing values\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum())  # Check for infinite values\n",
    "\n",
    "# Handle missing or infinite values\n",
    "# For example, you can drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Alternatively, you can replace infinite values with NaN or some other value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN after replacing infinite values\n",
    "\n",
    "# Separate independent variables (X) and dependent variable (y)\n",
    "X = df[['Lockdown', 'Treat', 'Treat*Lockdown']]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "y = df['value']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ae2b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -2.8399839227728862\n",
      "p-value: 0.05278542443000928\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\residential.csv\")\n",
    "\n",
    "# Assuming the column containing the time series data is named 'value'\n",
    "# Replace 'value' with the actual column name from your dataset\n",
    "time_series_column = 'value'\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller (ADF) test\n",
    "result = adfuller(data[time_series_column])\n",
    "\n",
    "# Extract and print the test statistic and p-value\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cc6e003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness and Kurtosis for Pre-COVID Sample:\n",
      "Skewness: 0.19651487005181847, Kurtosis: -1.342286368778722\n",
      "\n",
      "Skewness and Kurtosis for COVID Sample:\n",
      "Skewness: 0.5877970167575407, Kurtosis: -0.281295560019577\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\residential.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_skewness = skew(grouped_data.get_group(0)[co2_column])\n",
    "pre_covid_kurtosis = kurtosis(grouped_data.get_group(0)[co2_column])\n",
    "\n",
    "# Calculate skewness and kurtosis for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_skewness = skew(grouped_data.get_group(1)[co2_column])\n",
    "covid_kurtosis = kurtosis(grouped_data.get_group(1)[co2_column])\n",
    "\n",
    "# Print skewness and kurtosis for pre-COVID and COVID samples\n",
    "print(\"Skewness and Kurtosis for Pre-COVID Sample:\")\n",
    "print(f\"Skewness: {pre_covid_skewness}, Kurtosis: {pre_covid_kurtosis}\")\n",
    "print(\"\\nSkewness and Kurtosis for COVID Sample:\")\n",
    "print(f\"Skewness: {covid_skewness}, Kurtosis: {covid_kurtosis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dfeb15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Pre-COVID Sample:\n",
      "count    425.000000\n",
      "mean       0.106459\n",
      "std        0.039274\n",
      "min        0.058751\n",
      "25%        0.063897\n",
      "50%        0.109992\n",
      "75%        0.141314\n",
      "max        0.195069\n",
      "Name: value, dtype: float64\n",
      "\n",
      "Descriptive Statistics for COVID Sample:\n",
      "count    426.000000\n",
      "mean       0.103030\n",
      "std        0.037414\n",
      "min        0.058751\n",
      "25%        0.064251\n",
      "50%        0.101217\n",
      "75%        0.128965\n",
      "max        0.208933\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "# Assuming your dataset is already loaded into a DataFrame named 'data'\n",
    "data = pd.read_csv(r\"C:\\Users\\Shobhan Sarkar\\OneDrive\\Desktop\\project thiru\\spain\\residential.csv\")\n",
    "\n",
    "# Assuming the column containing CO2 emissions is named 'value'\n",
    "# Assuming the column indicating pre-COVID (0) or COVID (1) sample is named 'Treat'\n",
    "# Replace 'value' and 'Treat' with the actual column names from your dataset\n",
    "co2_column = 'value'\n",
    "treat_column = 'Treat'\n",
    "\n",
    "# Group the data by the 'Treat' column\n",
    "grouped_data = data.groupby(treat_column)\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the pre-COVID sample (Treat == 0)\n",
    "pre_covid_stats = grouped_data.get_group(0)[co2_column].describe()\n",
    "\n",
    "# Calculate descriptive statistics for CO2 emissions in the COVID sample (Treat == 1)\n",
    "covid_stats = grouped_data.get_group(1)[co2_column].describe()\n",
    "\n",
    "# Print the statistics for pre-COVID and COVID samples\n",
    "print(\"Descriptive Statistics for Pre-COVID Sample:\")\n",
    "print(pre_covid_stats)\n",
    "print(\"\\nDescriptive Statistics for COVID Sample:\")\n",
    "print(covid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf8d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
